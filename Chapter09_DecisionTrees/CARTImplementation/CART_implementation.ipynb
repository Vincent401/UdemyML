{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_func(\n",
    "    sample: np.ndarray,\n",
    "    feature_i: int,\n",
    "    threshold: float,\n",
    ") -> bool:\n",
    "    return sample[feature_i] >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_on_feature(\n",
    "    x: np.ndarray,\n",
    "    feature_i: int,\n",
    "    threshold: float,\n",
    ") -> np.ndarray:\n",
    "    x1 = np.array(\n",
    "        [sample for sample in x if split_func(sample, feature_i, threshold)],\n",
    "    )\n",
    "    x2 = np.array(\n",
    "        [\n",
    "            sample\n",
    "            for sample in x\n",
    "            if not split_func(sample, feature_i, threshold)\n",
    "        ],\n",
    "    )\n",
    "    return np.array([x1, x2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x: float) -> float:\n",
    "    return math.log(x) / math.log(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(y: np.ndarray) -> float:\n",
    "    unique_labels = np.unique(y)\n",
    "    entropy = 0.0\n",
    "    for label in unique_labels:\n",
    "        count = len(y[y == label])\n",
    "        p = count / len(y)\n",
    "        entropy += -p * log2(p)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_information_gain(\n",
    "    y: np.ndarray,\n",
    "    y1: np.ndarray,\n",
    "    y2: np.ndarray,\n",
    ") -> float:\n",
    "    p = len(y1) / len(y)\n",
    "    entropy = calculate_entropy(y)\n",
    "    return entropy - p * calculate_entropy(y1) - (1 - p) * calculate_entropy(y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(y: np.ndarray) -> float:\n",
    "    most_common = 0.0\n",
    "    max_count = 0\n",
    "    for label in np.unique(y):\n",
    "        count = len(y[y == label])\n",
    "        if count > max_count:\n",
    "            most_common = label\n",
    "            max_count = count\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_i: int | None = None,\n",
    "        threshold: float | None = None,\n",
    "        value: float | None = None,\n",
    "        true_branch: DecisionNode | None = None,\n",
    "        false_branch: DecisionNode | None = None,\n",
    "    ) -> None:\n",
    "        self.feature_i = feature_i\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_samples_split: int = 2,\n",
    "        min_impurity: float = 1e-7,\n",
    "        max_depth: float = np.inf,\n",
    "    ) -> None:\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        self.root = self._build_tree(x, y)\n",
    "\n",
    "    def _build_tree(self, x: np.ndarray, y: np.ndarray, current_depth: int = 0):\n",
    "        largest_impurity = 0.0\n",
    "        best_criteria = {}\n",
    "        best_sets = {}\n",
    "\n",
    "        # Add y as last column of x\n",
    "        Xy = np.concatenate((x, y.reshape(-1, 1)), axis=1)  # Fix shape bug here\n",
    "        n_samples, n_features = np.shape(Xy)  # Fix shape bug here\n",
    "\n",
    "        if (\n",
    "            n_samples >= self.min_samples_split\n",
    "            and current_depth <= self.max_depth\n",
    "        ):\n",
    "            # Calculate the impurity for each feature\n",
    "            # [[1, 2], [1, -1]]\n",
    "            for feature_i in range(n_features):\n",
    "                # All values of feature_i\n",
    "                feature_values = Xy[:, feature_i]  # [[1], [1]]\n",
    "                unique_values = np.unique(feature_values)  # [[1]]\n",
    "\n",
    "                # Iterate through all unique values of feature column i and\n",
    "                # calculate the impurity\n",
    "                for threshold in unique_values:  # [1]\n",
    "                    # Divide x and y depending on if the feature value\n",
    "                    # of x at index feature_i meets the threshold\n",
    "                    Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
    "\n",
    "                    if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "                        # Select the y-values of the two sets\n",
    "                        y1 = Xy1[:, n_features:]\n",
    "                        y2 = Xy2[:, n_features:]\n",
    "\n",
    "                        # Calculate impurity\n",
    "                        impurity = calculate_information_gain(y, y1, y2)\n",
    "\n",
    "                        # If this threshold resulted in a higher information\n",
    "                        # gain than previously recorded save the threshold value\n",
    "                        # and the feature index\n",
    "                        if impurity > largest_impurity:\n",
    "                            largest_impurity = impurity\n",
    "                            best_criteria = {\n",
    "                                \"feature_i\": feature_i,\n",
    "                                \"threshold\": threshold,\n",
    "                            }\n",
    "                            best_sets = {\n",
    "                                \"x_left\": Xy1[:, :n_features],\n",
    "                                \"y_left\": Xy1[:, n_features:],\n",
    "                                \"x_right\": Xy2[:, :n_features],\n",
    "                                \"y_right\": Xy2[:, n_features:],\n",
    "                            }\n",
    "\n",
    "        if largest_impurity > self.min_impurity:\n",
    "            # Build subtrees for the right and left branches\n",
    "            true_branch = self._build_tree(\n",
    "                best_sets[\"x_left\"],\n",
    "                best_sets[\"y_left\"],\n",
    "                current_depth + 1,\n",
    "            )\n",
    "            false_branch = self._build_tree(\n",
    "                best_sets[\"x_right\"],\n",
    "                best_sets[\"y_right\"],\n",
    "                current_depth + 1,\n",
    "            )\n",
    "            return DecisionNode(\n",
    "                feature_i=best_criteria[\"feature_i\"],\n",
    "                threshold=best_criteria[\"threshold\"],\n",
    "                true_branch=true_branch,\n",
    "                false_branch=false_branch,\n",
    "            )\n",
    "\n",
    "        # We're at leaf => determine value\n",
    "        leaf_value = majority_vote(y)\n",
    "        return DecisionNode(value=leaf_value)\n",
    "\n",
    "    def predict_value(self, x: np.ndarray, tree: DecisionNode | None = None):\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        # If we we're at a leaf => return value as the pred\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        # Choose the feature that we will test\n",
    "        feature_value = x[tree.feature_i]\n",
    "\n",
    "        # Determine if we go left or right branch\n",
    "        branch = tree.false_branch\n",
    "        if feature_value >= tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "\n",
    "        # Predict subtree\n",
    "        return self.predict_value(x, branch)\n",
    "\n",
    "    def predict(self, x: np.ndarray):\n",
    "        return np.array([self.predict_value(xi) for xi in x])\n",
    "\n",
    "    def score(self, x: np.ndarray, y: np.ndarray):\n",
    "        y_pred = self.predict(x)\n",
    "        true_pred = np.sum(\n",
    "            [y_pred_i == y_i for y_pred_i, y_i in zip(y_pred, y)],\n",
    "        )\n",
    "        n = len(y)\n",
    "        return true_pred / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m ClassificationTree()\n\u001b[1;32m----> 5\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[0;32m      7\u001b[0m score \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mscore(x_train, y_train)\n",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mClassificationTree.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: np\u001b[38;5;241m.\u001b[39mndarray, y: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(x, y)\n",
      "Cell \u001b[1;32mIn[21], line 41\u001b[0m, in \u001b[0;36mClassificationTree._build_tree\u001b[1;34m(self, x, y, current_depth)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Iterate through all unique values of feature column i and\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# calculate the impurity\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m unique_values:  \u001b[38;5;66;03m# [1]\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Divide x and y depending on if the feature value\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of x at index feature_i meets the threshold\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     Xy1, Xy2 \u001b[38;5;241m=\u001b[39m divide_on_feature(Xy, feature_i, threshold)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Xy1) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Xy2) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# Select the y-values of the two sets\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         y1 \u001b[38;5;241m=\u001b[39m Xy1[:, n_features:]\n",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m, in \u001b[0;36mdivide_on_feature\u001b[1;34m(x, feature_i, threshold)\u001b[0m\n\u001b[0;32m      6\u001b[0m x1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m      7\u001b[0m     [sample \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m split_func(sample, feature_i, threshold)],\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m x2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m     10\u001b[0m     [\n\u001b[0;32m     11\u001b[0m         sample\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     ],\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x1, x2])\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "x_train = np.random.uniform(-2, 2, size=(5, 3))\n",
    "y_train = np.random.randint(0, 2, size=(5, 1))\n",
    "\n",
    "clf = ClassificationTree()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)\n",
    "score = clf.score(x_train, y_train)\n",
    "print(f\"Accuracy: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
